# -*- coding: utf-8 -*-
"""HW2-2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jnRR8-ny4rrcDZR0TxDsSIwWpSlzSvC9

# FASHION MNIST dataset
"""

# Commented out IPython magic to ensure Python compatibility.
import sklearn
assert sklearn.__version__ >= "0.20"

# Common imports
import numpy as np
import os

# to make this notebook's output stable across runs
np.random.seed(42)

# To plot pretty figures
# %matplotlib inline
import matplotlib as mpl
import matplotlib.pyplot as plt
mpl.rc('axes', labelsize=14)
mpl.rc('xtick', labelsize=12)
mpl.rc('ytick', labelsize=12)

# Where to save the figures
PROJECT_ROOT_DIR = "."
CHAPTER_ID = "classification"
IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, "images", CHAPTER_ID)
os.makedirs(IMAGES_PATH, exist_ok=True)

def save_fig(fig_id, tight_layout=True, fig_extension="png", resolution=300):
    path = os.path.join(IMAGES_PATH, fig_id + "." + fig_extension)
    print("Saving figure", fig_id)
    if tight_layout:
        plt.tight_layout()
    plt.savefig(path, format=fig_extension, dpi=resolution)

import tensorflow as tf
import gzip

fashion_mnist = tf.keras.datasets.fashion_mnist

(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()

X_train=X_train.reshape((X_train.shape[0], 28* 28))

X_test=X_test.reshape((X_test.shape[0], 28 *28))





"""# RANDOM FOREST"""

# Commented out IPython magic to ensure Python compatibility.
from sklearn.ensemble import RandomForestClassifier
from sklearn import datasets
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
# %matplotlib inline

clf1=RandomForestClassifier(n_estimators=10)

clf1.fit(X_train,y_train)

clf1.score(X_test,y_test)



"""# Extra-trees"""

from sklearn.ensemble import ExtraTreesClassifier

clf2=ExtraTreesClassifier(n_estimators=10)

clf2.fit(X_train,y_train)

clf2.score(X_test,y_test)



"""# SVM"""

from sklearn import svm
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split

clf3=svm.SVC(kernel='poly',probability=True,random_state=42)

clf3.fit(X_train,y_train)

clf3.score(X_test, y_test)

"""# SOFT VOTING"""

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import VotingClassifier

X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
y = np.array([1, 1, 1, 2, 2, 2])

eclf2 = VotingClassifier(estimators=[('rf', clf1), ('et', clf2), ('svm', clf3)],voting='soft')
eclf2 = eclf2.fit(X_test, y_test)

eclf2.score(X_test, y_test)







